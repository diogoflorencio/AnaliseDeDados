---
title: "Predição de Votação de Deputados"
author: "Diogo Florêncio"
date: "13 de novembro de 2017"
output:
  html_notebook:
    theme: readable 
    toc: true
    toc_float: true
    fig_width: 5
    fig_height: 4
editor_options: 
  chunk_output_type: inline
---

```{r}
library(tidyverse)
library(caret)
options(scipen = 4)
dados <- read.csv("../dados/eleicoes2014.csv", encoding = "latin1")
```

###Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

```{r}
#summary(dados)

#particionando os dados
trainIndex <- createDataPartition(dados$votos, p = .75, list = FALSE)
treino <- dados[trainIndex,]
teste <- dados[-trainIndex,]

#modelo Lasso

fitControl <- trainControl(method='cv', number = 10)

lasso.fit <- train(votos ~sequencial_candidato + numero_cadidato + UF + partido 
          + setor_economico_receita, data=dados, 
                  method='lasso', 
                  metric="RMSE",
                  tuneLength = 10,
                  trControl=fitControl)
```







Compare os três modelos em termos do erro RMSE de validação cruzada. (9 pts.)
Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais? (9 pts.)
Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada). (9 pts.)
Use esse último modelo treinado para prever os dados de teste que disponibilizaremos por meio da plataforma Kaggle: (a ser disponibilizado) (9 pts.)
